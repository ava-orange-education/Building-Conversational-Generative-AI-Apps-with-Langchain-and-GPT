{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwoN3ticX2Bo"
      },
      "source": [
        "### API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XG-jXgp57QDI"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('api_key')\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQHDIwwXCUXe"
      },
      "source": [
        "### Creating a Simple Chain with LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXgrdwnWWORl",
        "outputId": "63a89d29-8f70-4991-8a9c-034ecbe2bd8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.2 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -qU langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-HQ-eIeWFNm",
        "outputId": "c8931bd8-6698-478d-ba05-0f4c36ef974c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The capital of France is: {'country': 'France', 'text': 'The capital of France is Paris.'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "\n",
        "## Initialize OpenAI model using LangChain\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7, openai_api_key=openai_api_key)\n",
        "\n",
        "# Define a prompt template\n",
        "prompt_template = PromptTemplate.from_template(\"What is the capital of {country}?\")\n",
        "\n",
        "# Create a simple chain\n",
        "simple_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt_template\n",
        ")\n",
        "\n",
        "# Example usage\n",
        "country = \"France\"\n",
        "response = simple_chain.invoke({\"country\": country})\n",
        "print(f\"The capital of {country} is: {response}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4KnYzMJCIE0"
      },
      "source": [
        "### Prompts: Designing Effective Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D21MPBRmBvbu",
        "outputId": "6352ea5b-efef-4b79-d9a3-5f3ff5ea038f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary:\n",
            "Artificial Intelligence (AI) is advancing quickly and significantly affecting various sectors, including healthcare, finance, and education, through tools like chatbots and recommendation systems. As AI becomes more integrated into everyday life, it is essential to tackle challenges related to ethics, bias, and privacy.\n",
            "\n",
            "Questions:\n",
            "1. In what ways do you think the integration of AI tools, such as chatbots and recommendation systems, can enhance or hinder the learning experience in education? \n",
            "\n",
            "2. What potential ethical dilemmas do you foresee arising from the widespread use of AI in industries like healthcare and finance, and how might these dilemmas be addressed effectively?\n",
            "\n",
            "3. Considering the issues of bias and\n",
            "\n",
            "Explanation:\n",
            "Okay! Imagine you have a really big box of Lego bricks, and you're trying to build a really cool spaceship. \n",
            "\n",
            "Now, if you were using a regular computer (like a really fast Lego builder), it would take one piece at a time to put the spaceship together. It would try every possible way to build it, but it has to do it step by step,\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Step 1: Set your OpenAI API key\n",
        "# openai_api_key = \"your-api-key-here\"\n",
        "\n",
        "# Step 2: Define prompt templates\n",
        "# A template for summarizing text\n",
        "summary_prompt_template = \"\"\"\n",
        "You are an expert summarizer. Please provide a concise summary of the following text in 2-3 sentences:\n",
        "\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "# A template for generating questions based on text\n",
        "questions_prompt_template = \"\"\"\n",
        "You are a creative educator. Based on the following text, generate three thoughtful questions to encourage deeper understanding:\n",
        "\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "# A template for explaining concepts in simple terms\n",
        "explanation_prompt_template = \"\"\"\n",
        "You are an educator explaining complex ideas in simple terms. Explain the following concept in a way a 10-year-old could understand:\n",
        "\n",
        "{concept}\n",
        "\"\"\"\n",
        "\n",
        "# Step 3: Create PromptTemplate objects\n",
        "summary_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=summary_prompt_template\n",
        ")\n",
        "\n",
        "questions_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=questions_prompt_template\n",
        ")\n",
        "\n",
        "explanation_prompt = PromptTemplate(\n",
        "    input_variables=[\"concept\"],\n",
        "    template=explanation_prompt_template\n",
        ")\n",
        "\n",
        "# Step 4: Initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7, max_tokens=75, openai_api_key=openai_api_key)\n",
        "\n",
        "# Step 5: Create LLMChains\n",
        "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
        "questions_chain = LLMChain(llm=llm, prompt=questions_prompt)\n",
        "explanation_chain = LLMChain(llm=llm, prompt=explanation_prompt)\n",
        "\n",
        "# Step 6: Input examples\n",
        "text_to_summarize = \"\"\"\n",
        "Artificial Intelligence (AI) has rapidly evolved, impacting industries like healthcare, finance, and education. AI tools, such as chatbots and recommendation systems,\n",
        "are increasingly integrated into daily life. As AI advances, addressing challenges like ethical issues, bias, and privacy is crucial.\n",
        "\"\"\"\n",
        "\n",
        "concept_to_explain = \"Quantum computing\"\n",
        "\n",
        "# Step 7: Run the chains\n",
        "# Generate summary\n",
        "summary = summary_chain.run(text=text_to_summarize)\n",
        "print(\"Summary:\")\n",
        "print(summary)\n",
        "\n",
        "# Generate questions\n",
        "questions = questions_chain.run(text=text_to_summarize)\n",
        "print(\"\\nQuestions:\")\n",
        "print(questions)\n",
        "\n",
        "# Generate explanation\n",
        "explanation = explanation_chain.run(concept=concept_to_explain)\n",
        "print(\"\\nExplanation:\")\n",
        "print(explanation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBF6ALECXV8F"
      },
      "source": [
        "###  Memory: Maintaining Context Across Conversations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "511vclQLNlSv",
        "outputId": "1f996fa7-752c-4415-d6b2-a3f2629c7799"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-bbb634d2a4b7>:27: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(return_messages=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant: Hello! How can I assist you today? (Type 'exit' to quit)\n",
            "You: Tell me about artificial intelligence.\n",
            "Assistant: Artificial intelligence, or AI, is a branch of computer science that aims to create machines capable of performing tasks that typically require human intelligence. These tasks include problem-solving, understanding natural language, recognizing patterns, and learning from experience. AI can be categorized into two main types: narrow AI, which is designed to perform specific tasks (like virtual assistants or recommendation systems), and general AI\n",
            "You: How is it used in healthcare?\n",
            "Assistant: AI is transforming healthcare in numerous ways! Here are a few key applications:\n",
            "\n",
            "1. **Diagnostics**: AI algorithms can analyze medical images (like X-rays and MRIs) to help detect conditions such as cancer, often with accuracy that matches or exceeds human radiologists.\n",
            "\n",
            "2. **Predictive Analytics**: By analyzing patient data, AI can help predict disease outbreaks, patient\n",
            "You: That's interesting. What are its limitations?\n",
            "Assistant: AI has several limitations, despite its impressive capabilities. Here are a few key ones:\n",
            "\n",
            "1. **Lack of Understanding**: AI systems often lack true understanding and reasoning. They can analyze data and identify patterns but don't comprehend the context or meaning behind the information.\n",
            "\n",
            "2. **Bias and Fairness**: AI can inherit biases present in the training data, leading to unfair\n",
            "You: exit\n",
            "Assistant: Goodbye! Have a great day!\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Step 1: Set your OpenAI API key\n",
        "# openai_api_key = \"your-api-key-here\"\n",
        "\n",
        "# Step 2: Define prompt templates\n",
        "conversation_prompt_template = \"\"\"\n",
        "The following is a friendly and engaging conversation. Remember the context of previous messages while answering.\n",
        "\n",
        "Conversation history:\n",
        "{history}\n",
        "\n",
        "User: {user_input}\n",
        "Assistant:\n",
        "\"\"\"\n",
        "\n",
        "# Step 3: Create PromptTemplate for conversation\n",
        "conversation_prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"user_input\"],\n",
        "    template=conversation_prompt_template\n",
        ")\n",
        "\n",
        "# Step 4: Initialize ChatOpenAI model and memory\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7, max_tokens=75, openai_api_key=openai_api_key)\n",
        "memory = ConversationBufferMemory(return_messages=True)\n",
        "\n",
        "# Step 5: Create an LLMChain with memory\n",
        "conversation_chain = LLMChain(llm=llm, prompt=conversation_prompt, memory=memory)\n",
        "\n",
        "# Step 6: Interactive conversation\n",
        "def chat_with_memory():\n",
        "    print(\"Assistant: Hello! How can I assist you today? (Type 'exit' to quit)\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"Assistant: Goodbye! Have a great day!\")\n",
        "            break\n",
        "        # Get the assistant's response while maintaining context\n",
        "        response = conversation_chain.run(user_input=user_input)\n",
        "        print(f\"Assistant: {response}\")\n",
        "\n",
        "# Run the conversation loop\n",
        "if __name__ == \"__main__\":\n",
        "    chat_with_memory()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsOqeKMF1AZn"
      },
      "source": [
        "### Agents and Tools in LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMvs1VmU1k5S",
        "outputId": "7a8ca7ed-9ebe-4a52-92ad-f4ff55118901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.37 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.37)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.19 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.19)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.8.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.8)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain-community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.37->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (4.12.2)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=1da784fddbf175d6dbebcd450bbd70651fa141cca5b1e509b893125c6910bdb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain-community\n",
        "! pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBBgpP6eQNWv",
        "outputId": "34f7d1a7-0353-472e-bcd7-3f22d5ca09da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade --quiet  langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwUrAEajPW4N",
        "outputId": "442807e3-950b-4f36-a883-7844b035cf8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find information about LangChain.  A Wikipedia search should provide a good overview.\n",
            "Action: Wikipedia Search\n",
            "Action Input: \"LangChain\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: LangChain\n",
            "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of languag\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I need to find information about LangChain.  A Wikipedia search should provide a good overview.\n",
            "Action: Wikipedia Search\n",
            "Action Input: \"LangChain\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: LangChain\n",
            "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of languag\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: The Wikipedia search didn't return a complete enough summary. I'll try searching for more specific information about its purpose and functionality.\n",
            "Action: Wikipedia Search\n",
            "Action Input: \"LangChain framework applications\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: LangChain\n",
            "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of languag\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: The Wikipedia search is not providing detailed information.  I'll need to rely on my existing knowledge and potentially other resources (which I don't have access to in this context) to answer the question.\n",
            "\n",
            "Thought: I now know the final answer based on my existing knowledge.\n",
            "\n",
            "Final Answer: LangChain is a framework for developing applications powered by large language models (LLMs).  It simplifies the process of integrating LLMs by providing tools for managing prompts, chains of thought, memory, and more.  It aims to make it easier to build complex and powerful LLM-based applications.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "AI Response: LangChain is a framework for developing applications powered by large language models (LLMs).  It simplifies the process of integrating LLMs by providing tools for managing prompts, chains of thought, memory, and more.  It aims to make it easier to build complex and powerful LLM-based applications.\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.agents import AgentExecutor, Tool, initialize_agent\n",
        "from google.colab import userdata  # Required for fetching the API key in Google Colab\n",
        "\n",
        "# Function to initialize the Gemini AI model\n",
        "def initialize_gemini(api_key):\n",
        "    genai.configure(api_key=api_key)\n",
        "    # Use GoogleGenerativeAI from LangChain to wrap the Gemini model\n",
        "    return GoogleGenerativeAI(model='gemini-1.5-flash', temperature=0.7, google_api_key=api_key)\n",
        "\n",
        "# Function to set up the Wikipedia search tool\n",
        "def setup_wikipedia_tool():\n",
        "    wiki_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=250)\n",
        "    return WikipediaQueryRun(api_wrapper=wiki_wrapper)\n",
        "\n",
        "# Function to define the AI agent's prompt template\n",
        "def configure_prompt():\n",
        "    return ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", \"You are an AI assistant. Use the Wikipedia search tool for information retrieval.\"),\n",
        "            (\"human\", \"{user_query}\"),\n",
        "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# Function to create the AI agent with integrated tools\n",
        "def create_ai_agent(gemini_model, tool, prompt):\n",
        "    tools = [\n",
        "        Tool(\n",
        "            name=\"Wikipedia Search\",\n",
        "            func=tool.run,\n",
        "            description=\"Useful for when you need to answer questions about general knowledge. Input should be a search query.\",\n",
        "        )\n",
        "    ]\n",
        "    #return create_tool_calling_agent(gemini_model, [tool], prompt)\n",
        "    return initialize_agent(tools, gemini_model, verbose=True)  # Initialize agent directly\n",
        "\n",
        "# Function to execute the AI agent with Wikipedia search\n",
        "def run_agent_with_wikipedia(api_key, query):\n",
        "    # Initialize components\n",
        "    gemini_model = initialize_gemini(api_key)\n",
        "    wiki_tool = setup_wikipedia_tool()\n",
        "    ai_prompt = configure_prompt()\n",
        "\n",
        "    # Create the agent\n",
        "    assistant_agent = create_ai_agent(gemini_model, wiki_tool, ai_prompt)\n",
        "\n",
        "    # Run the agent with the query\n",
        "    return assistant_agent.run(query)\n",
        "\n",
        "# Fetch API key from Google Colab user data\n",
        "api_key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Example usage\n",
        "query = \"What is LangChain?\"\n",
        "response = run_agent_with_wikipedia(api_key, query)\n",
        "print(\"\\nAI Response:\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8lz0d59Ngl-"
      },
      "source": [
        "###  Connecting OpenAI with LangChain : summarizer and question generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p81WTD5VNeI9",
        "outputId": "5b2a2e83-0ee9-46da-b041-18b95f735f70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary:\n",
            "Artificial Intelligence (AI) has significantly transformed various industries, including healthcare, finance, and education, with tools like chatbots and autonomous vehicles becoming commonplace. However, the advancement of AI raises important ethical concerns related to bias, privacy, and decision-making that need to be addressed.\n",
            "\n",
            "Follow-Up Questions:\n",
            "1. What specific examples can you provide that illustrate how AI has been successfully implemented in healthcare, finance, and education, and what benefits have these industries experienced as a result?\n",
            "\n",
            "2. How can organizations ensure that AI systems are designed and deployed in a way that minimizes bias and protects user privacy while still achieving their intended outcomes?\n",
            "\n",
            "3. What frameworks or guidelines currently exist to address the ethical concerns surrounding AI decision-making, and how effective are they in practice?\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Define the prompt templates\n",
        "summary_prompt_template = \"\"\"\n",
        "Summarize the following text in 2-3 sentences:\n",
        "\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "questions_prompt_template = \"\"\"\n",
        "Based on the summary, generate three follow-up questions to explore the topic further:\n",
        "\n",
        "{summary}\n",
        "\"\"\"\n",
        "\n",
        "# Create PromptTemplate objects\n",
        "summary_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=summary_prompt_template\n",
        ")\n",
        "\n",
        "questions_prompt = PromptTemplate(\n",
        "    input_variables=[\"summary\"],\n",
        "    template=questions_prompt_template\n",
        ")\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7, openai_api_key=openai_api_key)\n",
        "\n",
        "# Create LLMChains\n",
        "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
        "questions_chain = LLMChain(llm=llm, prompt=questions_prompt)\n",
        "\n",
        "# Define input text\n",
        "input_text = \"\"\"\n",
        "Artificial Intelligence (AI) has rapidly evolved over the past decade, impacting industries such as healthcare, finance, and education.\n",
        "AI-powered tools like chatbots, recommendation systems, and autonomous vehicles are becoming integral parts of daily life.\n",
        "As AI continues to advance, ethical considerations around bias, privacy, and decision-making remain key challenges to address.\n",
        "\"\"\"\n",
        "\n",
        "# Run the chains\n",
        "# Generate summary\n",
        "summary = summary_chain.run(text=input_text)\n",
        "print(\"Summary:\")\n",
        "print(summary)\n",
        "\n",
        "# Generate follow-up questions\n",
        "questions = questions_chain.run(summary=summary)\n",
        "print(\"\\nFollow-Up Questions:\")\n",
        "print(questions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsIfwWS3ag6n"
      },
      "source": [
        "### Hugging Face Language Models in LangChain : QA chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0QRksB_aGms"
      },
      "outputs": [],
      "source": [
        "! pip install -qU langchain-openai\n",
        "! pip install langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799,
          "referenced_widgets": [
            "005ca4bac68d4b0f90d204b530c63e92",
            "b26e5b3983c147d9aa064bf4b0ecb298",
            "2a3379b48f224b24bf09d14f3ec4cb13",
            "9e5980b982d941d7ad6715980ff6235a",
            "5fdbf2f68ca1420a8d542ff2ebce3536",
            "7ae26387e066462ea73528c0c7223c81",
            "1f400633c73c41cab008e1eb40d36ce7",
            "42258582d29048ffb55f1aa1d25597b9",
            "eb25091e87a041dc9bcc4570b41e92fb",
            "9bc36e1c51bb4d129cb6795061584a3f",
            "c5e415725dd74927ab49a7484e9f8ad7",
            "a3953e6d0b1a4fd0ba52c3db9d219ae8",
            "5a644c1000cf413c89d58669b606c226",
            "3e488c2ca1a84a3c8a860e029ea280eb",
            "4e6ba89bc2cb4921bb7e5663b00a3218",
            "10103f494b1a49988068dbc25147c2f7",
            "b7aa8094a6324c15ad59c468aefc5f6b",
            "2271a1eb600b42609cda870a7b3a211a",
            "ca30bdb50f1e4b01815cd201579c4d6b",
            "c69edbbaf7404277b4d055ceec7c21c3",
            "df8db2b7f66b4fd2b2ec45f04b7c3b6d",
            "1e315d1f8ddc4a618c897b90e77df162",
            "93758134ce924fc196639a80c8d4f63f",
            "077165f005de4a6b87a560a2e7f0e94c",
            "331102a50d934aab9e25c5b40819c5d7",
            "8e438e05f89743a1817d810778866ecf",
            "93098dc5de7c45eabe51bff0337d1f10",
            "704b0ef901b64e3389af8d9e33be826e",
            "777337d1fb8d4645aa85cc08eae1482e",
            "af155b9e6a794c488a7b1b90aa0038b7",
            "b788d4456d164f1baf926d8c8a7884af",
            "254d0794e13c49589008a5b29545aec7",
            "ba584a2630cf4354b7f917b25848c381",
            "f22ae8c4f3b946f394a5d4178a145ed9",
            "76089b2deb994810a46379c014c54914",
            "4fd33b6c22b74cefb3e0756161ce6027",
            "c26c1c128d2849c9a7bd894e02226ddf",
            "8d0597472073474dab15187e63db8572",
            "a53ff4ae1a3b4544b468c383fc5a4ae2",
            "79342a20ae5d4cb7b9936fc02d60e0ad",
            "2b3e94f24e4a4ae898959f30a07aa6cd",
            "ba34a5ccfdfb49ef8ba86720be82ccd8",
            "14ae44d49abd4966b56d200ce0d475b2",
            "572992a0e6194efd83d5eb0359ebd8ad",
            "ca1673cda7d040359f3f45388e1fdb2d",
            "3a6ec1a1618d47ef9396bcec3471e2b5",
            "c28a811dc70c4caca90286e71841572d",
            "2bfa60654c844522aa38191966fda4c2",
            "01a300c381d34c859afb497f5d5370ae",
            "45c2c8a90ced4c9d89c2d4dabbe27745",
            "3ede478d731840dcba839f7c23e32bfe",
            "3c33145f7bef4b97aae17debd6a1b111",
            "9dbcef214b2640719ef8b688b115e34d",
            "bad968a9c2414047a7da01dd367b86c5",
            "0faa60c7e4d1489f84201e294af50605",
            "965d65d80b9b48fe98fa3c4eef075256",
            "bcdf41ffdd134398bfaf385ab270d274",
            "0766631d202c42bead24037dd371ba7c",
            "1f5ce74cbc574891975739714c1d0872",
            "83918cbdcce24b23bf3e056500ea7b99",
            "538d3a1df1d147ebbbc1c9dd84244745",
            "b6d4e89ffacd41fdae6127d3c8c29846",
            "f6e8bda5095f48cf89c2eb0932b60c39",
            "63d3c3c3d1254b05ac64684a4841430e",
            "d4bfd36b012b440c92cb549df2cd5d2e",
            "c7378066f04a4f18a9bb453122f6c678",
            "85cd0b0abc7a46aaa58fc614e3b60ef4",
            "6a9ae6b68803407caa443010973d21a0",
            "8b8073757893424fb4f382753e42bd97",
            "cd2035b8598d4e899518f6f31214f89a",
            "74d27cf2fa1e4fe89042fdb10307f5a8",
            "b6210a88e2a645f680099104a6b5f795",
            "93cd4de065174ab9b957e49836781678",
            "db58a341cab549428f433ecc6ca7a5a9",
            "de8b9b9d94814745a471a7a0c6b35c88",
            "8907d8321a0c4e93a1afc0edd5c5e12e",
            "8eba9caabc284601bda2dccd9d481b60"
          ]
        },
        "id": "1krYvlnZNlV_",
        "outputId": "d130dfcc-7496-4da2-b4ff-9074c0f29a40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "005ca4bac68d4b0f90d204b530c63e92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3953e6d0b1a4fd0ba52c3db9d219ae8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93758134ce924fc196639a80c8d4f63f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f22ae8c4f3b946f394a5d4178a145ed9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca1673cda7d040359f3f45388e1fdb2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "965d65d80b9b48fe98fa3c4eef075256",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85cd0b0abc7a46aaa58fc614e3b60ef4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "<ipython-input-9-e9d46b027702>:40: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  llm_chain = LLMChain(llm=hf_llm, prompt=prompt)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant is ready. Type your question (or type 'exit' to quit).\n",
            "You: What are the applications of artificial intelligence?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-e9d46b027702>:50: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = llm_chain.run(question=question)\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant: \n",
            "You are an assistant with deep knowledge in various domains. Answer the user's question thoughtfully and accurately.\n",
            "\n",
            "Question: What are the applications of artificial intelligence?\n",
            "\n",
            "Answer:\n",
            "\n",
            "The following applications are designed to provide a natural human understanding of the world.\n",
            "\n",
            "Computer Vision\n",
            "\n",
            "Computer Vision is a form of artificial intelligence that makes sense of the world. It is able to recognize complex faces and make predictions.\n",
            "\n",
            "Computer Vision is also able to analyze the data of human\n",
            "You: exit\n",
            "Assistant: Goodbye!\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain_huggingface.llms import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "# Step 1: Set up the Hugging Face model and tokenizer\n",
        "model_name = \"gpt2\"  # You can replace this with a larger model like 'EleutherAI/gpt-neo-2.7B'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Step 2: Create a Hugging Face pipeline\n",
        "hf_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=100,\n",
        "    temperature=0.7,\n",
        "    top_k=50,\n",
        "    top_p=0.95\n",
        ")\n",
        "\n",
        "# Step 3: Wrap the Hugging Face pipeline in LangChain\n",
        "hf_llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
        "\n",
        "# Step 4: Define a prompt template\n",
        "prompt_template = \"\"\"\n",
        "You are an assistant with deep knowledge in various domains. Answer the user's question thoughtfully and accurately.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Create a PromptTemplate object\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=prompt_template\n",
        ")\n",
        "\n",
        "# Step 5: Create an LLMChain\n",
        "llm_chain = LLMChain(llm=hf_llm, prompt=prompt)\n",
        "\n",
        "# Step 6: User Interaction\n",
        "def ask_question():\n",
        "    print(\"Assistant is ready. Type your question (or type 'exit' to quit).\")\n",
        "    while True:\n",
        "        question = input(\"You: \")\n",
        "        if question.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"Assistant: Goodbye!\")\n",
        "            break\n",
        "        response = llm_chain.run(question=question)\n",
        "        print(f\"Assistant: {response}\")\n",
        "\n",
        "# Start the assistant\n",
        "if __name__ == \"__main__\":\n",
        "    ask_question()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkOsNggYclVq"
      },
      "source": [
        "### Customizing Language Models for Specific Use Case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKYRuPB-Nle4",
        "outputId": "dba925a8-6c5d-4c0f-fbc1-5c441d542b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Data:\n",
            "                                                text expected_sentiment\n",
            "0           I love this product! It works perfectly.           Positive\n",
            "1    The service was terrible and I will not return.           Negative\n",
            "2      It's okay, but I expected more for the price.            Neutral\n",
            "3  Absolutely fantastic! Highly recommend to ever...           Positive\n",
            "4  Disappointed with the quality, not worth the m...           Negative\n",
            "\n",
            "Sentiment Analysis Results:\n",
            "                                                text expected_sentiment  \\\n",
            "0           I love this product! It works perfectly.           Positive   \n",
            "1    The service was terrible and I will not return.           Negative   \n",
            "2      It's okay, but I expected more for the price.            Neutral   \n",
            "3  Absolutely fantastic! Highly recommend to ever...           Positive   \n",
            "4  Disappointed with the quality, not worth the m...           Negative   \n",
            "\n",
            "   predicted_sentiment  \n",
            "0  Sentiment: Positive  \n",
            "1  Sentiment: Negative  \n",
            "2   Sentiment: Neutral  \n",
            "3  Sentiment: Positive  \n",
            "4  Sentiment: Negative  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# # Step 1: Set your OpenAI API key\n",
        "# openai_api_key = \"your-api-key-here\"\n",
        "\n",
        "# Step 2: Generate sample data for sentiment analysis\n",
        "def generate_sample_data():\n",
        "    data = {\n",
        "        \"text\": [\n",
        "            \"I love this product! It works perfectly.\",\n",
        "            \"The service was terrible and I will not return.\",\n",
        "            \"It's okay, but I expected more for the price.\",\n",
        "            \"Absolutely fantastic! Highly recommend to everyone.\",\n",
        "            \"Disappointed with the quality, not worth the money.\",\n",
        "        ],\n",
        "        \"expected_sentiment\": [\n",
        "            \"Positive\",\n",
        "            \"Negative\",\n",
        "            \"Neutral\",\n",
        "            \"Positive\",\n",
        "            \"Negative\",\n",
        "        ],\n",
        "    }\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Step 3: Define a prompt template for sentiment analysis\n",
        "sentiment_prompt_template = \"\"\"\n",
        "You are an AI sentiment analyzer. Analyze the sentiment of the following text and classify it as Positive, Negative, or Neutral.\n",
        "\n",
        "Text: {text}\n",
        "\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=sentiment_prompt_template\n",
        ")\n",
        "\n",
        "# Step 4: Initialize the OpenAI LLM model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.0,  # Focus on deterministic outputs for classification\n",
        "    openai_api_key=openai_api_key\n",
        ")\n",
        "\n",
        "# Step 5: Create an LLMChain\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Step 6: Sentiment analysis function\n",
        "def analyze_sentiment(df, llm_chain):\n",
        "    df[\"predicted_sentiment\"] = df[\"text\"].apply(lambda text: llm_chain.run(text=text))\n",
        "    return df\n",
        "\n",
        "# Step 7: Main workflow\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate sample data\n",
        "    df = generate_sample_data()\n",
        "    print(\"Sample Data:\")\n",
        "    print(df)\n",
        "\n",
        "    # Perform sentiment analysis\n",
        "    df = analyze_sentiment(df, llm_chain)\n",
        "\n",
        "    # Show results\n",
        "    print(\"\\nSentiment Analysis Results:\")\n",
        "    print(df)\n",
        "\n",
        "    # Evaluate performance (optional)\n",
        "    correct_predictions = (df[\"expected_sentiment\"] == df[\"predicted_sentiment\"]).sum()\n",
        "    accuracy = correct_predictions / len(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMKhSEIAmE7B"
      },
      "source": [
        "### Conversational Agent with LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO2uBSIllHga",
        "outputId": "1f138bd8-c6b4-4f85-c87a-78c0f7186250"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-060dfcd9cb8a>:26: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"history\")\n",
            "<ipython-input-18-060dfcd9cb8a>:36: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  conversation_chain = ConversationChain(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversational Agent: Hello! How can I assist you today?\n",
            "You: Can you recommend a good movie?\n",
            "Conversational Agent: Sure! What genre are you interested in? Action, drama, comedy, or something else?\n",
            "You: I like comedies.\n",
            "Conversational Agent: Great choice! If you enjoy comedies, I recommend \"Superbad.\" It's a hilarious coming-of-age film that follows two high school friends on a wild night out. Another option is \"The Grand Budapest Hotel,\" which combines humor with stunning visuals and a quirky storyline. Do either of these sound good to you?\n",
            "You:  Thanks!\n",
            "Conversational Agent: You're welcome! If you end up watching one of those movies, I'd love to hear what you think. If you need more recommendations or anything else, just let me know!\n",
            "You: exit\n",
            "Conversational Agent: Goodbye! Have a great day!\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# # Step 1: Set up your OpenAI API key\n",
        "# openai_api_key = \"your-api-key-here\"\n",
        "\n",
        "# Step 2: Define a prompt template\n",
        "conversation_prompt_template = \"\"\"\n",
        "You are a highly intelligent conversational agent. You remember the context of the conversation and respond thoughtfully to the user's queries.\n",
        "\n",
        "Here is the conversation so far:\n",
        "{history}\n",
        "\n",
        "User: {input}\n",
        "Assistant:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"],\n",
        "    template=conversation_prompt_template\n",
        ")\n",
        "\n",
        "# Step 3: Set up ConversationBufferMemory to store conversation history\n",
        "memory = ConversationBufferMemory(memory_key=\"history\")\n",
        "\n",
        "# Step 4: Initialize the OpenAI LLM model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.7,\n",
        "    openai_api_key=openai_api_key\n",
        ")\n",
        "\n",
        "# Step 5: Create a ConversationChain\n",
        "conversation_chain = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    prompt=prompt\n",
        ")\n",
        "\n",
        "# Step 6: Interactive Chat Function\n",
        "def chat_with_agent():\n",
        "    print(\"Conversational Agent: Hello! How can I assist you today?\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "            print(\"Conversational Agent: Goodbye! Have a great day!\")\n",
        "            break\n",
        "        response = conversation_chain.run(input=user_input)\n",
        "        print(f\"Conversational Agent: {response}\")\n",
        "\n",
        "# Step 7: Start the Chat\n",
        "if __name__ == \"__main__\":\n",
        "    chat_with_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX0GerQzUGnV"
      },
      "source": [
        "### Multi Agent chatbot with langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coJSIKHASWaK",
        "outputId": "80faaaa2-7b70-4b62-ef47-8c6080982b90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/411.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m409.6/411.6 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/454.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -qU langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezKaFk6fGL0h"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.agents import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J142NJqXRBiD",
        "outputId": "08e121e0-a37b-49b2-87fc-5680ee533ed3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent 1 (Query): Generative AI refers to a class of artificial intelligence models that are designed to create new content, such as text, images, music, or other media, based on the patterns and structures learned from existing data. Unlike traditional AI systems, which primarily focus on classification or regression tasks, generative AI aims to produce original outputs that resemble the training data.\n",
            "\n",
            "Key aspects of generative AI include:\n",
            "\n",
            "1. **Learning from Data**: Generative models are trained on large datasets to understand the underlying distribution of\n",
            "Agent 2 (Answer): the data, enabling them to generate new samples that are similar to the training examples.\n",
            "\n",
            "2. **Types of Models**: Common types of generative AI models include Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer-based models, each with unique mechanisms for content generation.\n",
            "\n",
            "3. **Applications**: Generative AI has a wide range of applications, including art creation, music composition, text generation, video synthesis, and even drug discovery.\n",
            "\n",
            "4\n",
            "Agent 3 (Explanation): Generative AI refers to a class of artificial intelligence techniques that enable machines to produce new content based on patterns learned from existing data. Let’s break down and elaborate on each point mentioned in your response:\n",
            "\n",
            "### 1. **Understanding Generative AI**:\n",
            "Generative AI models are designed to analyze a training dataset and learn the underlying distribution of that data. By understanding this distribution, these models can create new data points that are similar to those in the training set. This process involves:\n",
            "\n",
            "- **Data\n",
            "Summary of Explanation: 1. **Definition of Generative AI**: Generative AI encompasses AI techniques that allow machines to generate new content by learning patterns from existing data.\n",
            "\n",
            "2. **Training Process**: These models analyze a training dataset to understand its underlying distribution, enabling them to create new data points resembling the original data.\n",
            "\n",
            "3. **Content Creation**: The ability to produce new, similar content is a fundamental feature of generative AI, which relies on the insights gained from the training data.\n"
          ]
        }
      ],
      "source": [
        "# Initialize the OpenAI API with your API key\n",
        "#openai.api_key = \"your-api-key-here\"\n",
        "\n",
        "# Step 1: Set up the OpenAI chat model\n",
        "chat_model = ChatOpenAI(\n",
        "              model=\"gpt-4o-mini\",\n",
        "              max_tokens=100,\n",
        "              temperature=0.7,\n",
        "              openai_api_key=openai_api_key)\n",
        "\n",
        "# Step 2: Create memory to store the conversation history (if needed)\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "# Step 3: Define Tools for Agents\n",
        "@tool\n",
        "def summarize_response(response: str) -> str:\n",
        "    \"\"\"Summarizes the generated response from an agent.\"\"\"\n",
        "    summary_prompt_template = \"Summarize the following response into 3 key points:\\n{response}\"\n",
        "    summary_prompt = PromptTemplate(\n",
        "        input_variables=[\"response\"],\n",
        "        template=summary_prompt_template,\n",
        "    )  # Create a PromptTemplate object\n",
        "    summary_chain = LLMChain(llm=chat_model, prompt=summary_prompt)\n",
        "    summary = summary_chain.run(response=response) # Run with the 'response' variable\n",
        "    return summary\n",
        "\n",
        "@tool\n",
        "def explain_concept(response: str) -> str:\n",
        "    \"\"\"Explains the concept in detail based on the generated response.\"\"\"\n",
        "    explain_prompt = \"Provide a detailed explanation for the following response:\\n\" + response\n",
        "    # Create a PromptTemplate object instead of directly using a string\n",
        "    prompt_template = PromptTemplate(\n",
        "        input_variables=[\"input_text\"],\n",
        "        template=explain_prompt\n",
        "    )\n",
        "    explanation_chain = LLMChain(llm=chat_model, prompt=prompt_template)  # Use prompt_template here\n",
        "    explanation = explanation_chain.run(input_text=response)\n",
        "    return explanation\n",
        "\n",
        "# Step 4: Define agent behaviors using LangChain's tools\n",
        "def create_agents(model):\n",
        "    # Agent 1: Asks a question\n",
        "    query_agent = ChatOpenAI(model=model, max_tokens=100, temperature=0.7, openai_api_key=openai_api_key)\n",
        "\n",
        "    # Agent 2: Provides a short answer\n",
        "    answer_agent = ChatOpenAI(model=model, max_tokens=100, temperature=0.7, openai_api_key=openai_api_key)\n",
        "\n",
        "    # Agent 3: Uses tools to summarize or explain the response\n",
        "    explanation_agent = ChatOpenAI(model=model, max_tokens=100, temperature=0.7, openai_api_key=openai_api_key)\n",
        "\n",
        "    # Initialize the agents using LangChain\n",
        "    agents = [\n",
        "        {\n",
        "            \"role\": \"query\",\n",
        "            \"agent\": query_agent,\n",
        "            \"task\": \"Ask a question about GEN AI.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"answer\",\n",
        "            \"agent\": answer_agent,\n",
        "            \"task\": \"Provide a brief answer to the question.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"explain\",\n",
        "            \"agent\": explanation_agent,\n",
        "            \"task\": \"Explain the concept in more detail.\"\n",
        "        }\n",
        "    ]\n",
        "    return agents\n",
        "\n",
        "# Step 5: Create Multi-Agent Interaction\n",
        "def interact_with_agents():\n",
        "    # Get agents ready\n",
        "    model=\"gpt-4o-mini\"\n",
        "    agents = create_agents(model)\n",
        "\n",
        "    # Agent 1 (Query Agent) asks a question\n",
        "    query = \"What is Generative AI?\"\n",
        "    query_response = agents[0][\"agent\"].generate([query])\n",
        "    print(f\"Agent 1 (Query): {query_response.generations[0][0].text}\")  # Extract text from LLMResult\n",
        "\n",
        "    # Agent 2 (Answer Agent) provides an answer to the question\n",
        "    answer = agents[1][\"agent\"].generate([f\"Answer the following question briefly: {query_response.generations[0][0].text}\"])  # Extract text from LLMResult\n",
        "    print(f\"Agent 2 (Answer): {answer.generations[0][0].text}\")  # Extract text from LLMResult\n",
        "\n",
        "    # Agent 3 (Explanation Agent) explains the answer in more detail\n",
        "    # Pass the text content of the answer to explain_concept\n",
        "    explanation = explain_concept(answer.generations[0][0].text)\n",
        "    print(f\"Agent 3 (Explanation): {explanation}\")\n",
        "\n",
        "    # Optionally, Agent 3 can summarize the response\n",
        "    # Pass the text content of the explanation to summarize_response\n",
        "    summary = summarize_response(explanation)\n",
        "    print(f\"Summary of Explanation: {summary}\")\n",
        "\n",
        "# Run the multi-agent interaction\n",
        "interact_with_agents()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4Qzz2rMScVI"
      },
      "source": [
        "### Q&A Bot based on Retrieval-Augmented Generation (RAG) using Langchain and OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgD7Ih5DO_23",
        "outputId": "2dba9a10-3977-45c8-edef-cd29e844212a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (3.3.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.1.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.1.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.12.14)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.59.6)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.8.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.14 marshmallow-3.25.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers pypdf faiss-cpu\n",
        "!pip install langchain langchain-openai langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb8xGDyLPWwv"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxL1WgYVO_55",
        "outputId": "51426d83-513a-47ef-8535-a0d78eaf3cd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: MEMO RAG, or Memory-Augmented Retrieval-Augmented Generation, is a method that combines memory and retrieval to effectively handle complex queries. It utilizes a memory model to generate draft answers, which guide the search for relevant external information. A retriever then gathers pertinent data from databases, and a more powerful language model synthesizes this information to create a comprehensive final answer. This approach allows MEMO RAG to manage ambiguous queries and efficiently process large amounts of information across various tasks.\n"
          ]
        }
      ],
      "source": [
        "def load_document(file_path):\n",
        "    \"\"\"\n",
        "    Load a document from the specified file path.\n",
        "\n",
        "    Parameters:\n",
        "    - file_path (str): Path to the document file.\n",
        "\n",
        "    Returns:\n",
        "    - list: List of documents loaded from the file.\n",
        "    \"\"\"\n",
        "\n",
        "    document_loader = PyPDFLoader(file_path)\n",
        "    return document_loader.load()\n",
        "\n",
        "def segment_text_chunks(doc_list):\n",
        "    \"\"\"\n",
        "    Segment the loaded documents into smaller text chunks.\n",
        "\n",
        "    Parameters:\n",
        "    - doc_list (list): List of loaded documents.\n",
        "\n",
        "    Returns:\n",
        "    - list: List of text chunks.\n",
        "    \"\"\"\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter()\n",
        "    return text_splitter.split_documents(doc_list)\n",
        "\n",
        "def build_vector_store(text_data, embed_model=\"BAAI/bge-small-en-v1.5\"):\n",
        "    \"\"\"\n",
        "    Build a FAISS vector store from text chunks using HuggingFace embeddings.\n",
        "\n",
        "    Parameters:\n",
        "    - text_data (list): List of text chunks.\n",
        "    - embed_model (str): HuggingFace model name for embeddings.\n",
        "\n",
        "    Returns:\n",
        "    - FAISS: A vector store with the embedded text data.\n",
        "    \"\"\"\n",
        "\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=embed_model, encode_kwargs={\"normalize_embeddings\": True})\n",
        "    vector_storage = FAISS.from_documents(text_data, embedding_model)\n",
        "    vector_storage.save_local(\"unique_vector_store.db\")\n",
        "    return vector_storage\n",
        "\n",
        "def setup_retriever(vector_storage):\n",
        "    \"\"\"\n",
        "    Setup a retriever using the provided vector store.\n",
        "\n",
        "    Parameters:\n",
        "    - vector_storage (FAISS): The FAISS vector store.\n",
        "\n",
        "    Returns:\n",
        "    - Retriever: The configured retriever.\n",
        "    \"\"\"\n",
        "    return vector_storage.as_retriever()\n",
        "\n",
        "def initialize_language_model(model_identifier=\"gpt-4o-mini\"):\n",
        "    \"\"\"\n",
        "    Initialize the language model using the specified identifier.\n",
        "\n",
        "    Parameters:\n",
        "    - model_identifier (str): The model identifier.\n",
        "\n",
        "    Returns:\n",
        "    - ChatOpenAI: The initialized language model.\n",
        "    \"\"\"\n",
        "\n",
        "    return ChatOpenAI(model_name=model_identifier,\n",
        "                      max_tokens=100,\n",
        "                      temperature=0.7,\n",
        "                      openai_api_key=openai_api_key)\n",
        "\n",
        "def setup_prompt_template():\n",
        "    \"\"\"\n",
        "    Setup the prompt template for querying.\n",
        "\n",
        "    Returns:\n",
        "    - ChatPromptTemplate: The configured prompt template.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt_template_text = \"\"\"\n",
        "    You are an assistant for answering questions.\n",
        "    Please use the given context to respond to the following query:\n",
        "\n",
        "    <context>\n",
        "    {context}\n",
        "    </context>\n",
        "\n",
        "    Query: {input}\n",
        "    \"\"\"\n",
        "    return ChatPromptTemplate.from_template(prompt_template_text)\n",
        "\n",
        "def create_rag_pipeline(retriever_instance, language_model, prompt_config):\n",
        "    \"\"\"\n",
        "    Create the RAG pipeline using the retriever, language model, and prompt template.\n",
        "\n",
        "    Parameters:\n",
        "    - retriever_instance (Retriever): The retriever instance.\n",
        "    - language_model (ChatOpenAI): The language model instance.\n",
        "    - prompt_config (ChatPromptTemplate): The prompt template configuration.\n",
        "\n",
        "    Returns:\n",
        "    - Chain: The configured RAG chain.\n",
        "    \"\"\"\n",
        "\n",
        "    document_chain = create_stuff_documents_chain(language_model, prompt_config)\n",
        "    return create_retrieval_chain(retriever_instance, document_chain)\n",
        "\n",
        "def query_pipeline(pipeline_chain, input_query):\n",
        "    \"\"\"\n",
        "    Query the RAG pipeline with the provided input.\n",
        "\n",
        "    Parameters:\n",
        "    - pipeline_chain (Chain): The RAG pipeline.\n",
        "    - input_query (str): The user's input query.\n",
        "\n",
        "    Returns:\n",
        "    - str: The response from the pipeline.\n",
        "    \"\"\"\n",
        "    result = pipeline_chain.invoke({\"input\": input_query})\n",
        "    return result['answer']\n",
        "\n",
        "# Example usage\n",
        "def main():\n",
        "    # Load the document\n",
        "    loaded_docs = load_document(\"/content/RAG.pdf\")\n",
        "\n",
        "    # Split into text chunks\n",
        "    chunks = segment_text_chunks(loaded_docs)\n",
        "\n",
        "    # Create vector store\n",
        "    vector_storage = build_vector_store(chunks)\n",
        "\n",
        "    # Setup retriever\n",
        "    retriever = setup_retriever(vector_storage)\n",
        "\n",
        "    # Initialize language model\n",
        "    lang_model = initialize_language_model()\n",
        "\n",
        "    # Setup prompt template\n",
        "    prompt_config = setup_prompt_template()\n",
        "\n",
        "    # Create RAG pipeline\n",
        "    rag_pipeline = create_rag_pipeline(retriever, lang_model, prompt_config)\n",
        "\n",
        "    # Query the RAG pipeline\n",
        "    query = \"What is MEMO RAG?\"\n",
        "    response = query_pipeline(rag_pipeline, query)\n",
        "\n",
        "    print(\"Answer:\", response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaeLGSRLO_9T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "005ca4bac68d4b0f90d204b530c63e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b26e5b3983c147d9aa064bf4b0ecb298",
              "IPY_MODEL_2a3379b48f224b24bf09d14f3ec4cb13",
              "IPY_MODEL_9e5980b982d941d7ad6715980ff6235a"
            ],
            "layout": "IPY_MODEL_5fdbf2f68ca1420a8d542ff2ebce3536"
          }
        },
        "01a300c381d34c859afb497f5d5370ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0766631d202c42bead24037dd371ba7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6e8bda5095f48cf89c2eb0932b60c39",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63d3c3c3d1254b05ac64684a4841430e",
            "value": 548105171
          }
        },
        "077165f005de4a6b87a560a2e7f0e94c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_704b0ef901b64e3389af8d9e33be826e",
            "placeholder": "​",
            "style": "IPY_MODEL_777337d1fb8d4645aa85cc08eae1482e",
            "value": "vocab.json: 100%"
          }
        },
        "0faa60c7e4d1489f84201e294af50605": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10103f494b1a49988068dbc25147c2f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14ae44d49abd4966b56d200ce0d475b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e315d1f8ddc4a618c897b90e77df162": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f400633c73c41cab008e1eb40d36ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f5ce74cbc574891975739714c1d0872": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4bfd36b012b440c92cb549df2cd5d2e",
            "placeholder": "​",
            "style": "IPY_MODEL_c7378066f04a4f18a9bb453122f6c678",
            "value": " 548M/548M [00:03&lt;00:00, 175MB/s]"
          }
        },
        "2271a1eb600b42609cda870a7b3a211a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "254d0794e13c49589008a5b29545aec7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a3379b48f224b24bf09d14f3ec4cb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42258582d29048ffb55f1aa1d25597b9",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb25091e87a041dc9bcc4570b41e92fb",
            "value": 26
          }
        },
        "2b3e94f24e4a4ae898959f30a07aa6cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bfa60654c844522aa38191966fda4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bad968a9c2414047a7da01dd367b86c5",
            "placeholder": "​",
            "style": "IPY_MODEL_0faa60c7e4d1489f84201e294af50605",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 23.8MB/s]"
          }
        },
        "331102a50d934aab9e25c5b40819c5d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af155b9e6a794c488a7b1b90aa0038b7",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b788d4456d164f1baf926d8c8a7884af",
            "value": 1042301
          }
        },
        "3a6ec1a1618d47ef9396bcec3471e2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45c2c8a90ced4c9d89c2d4dabbe27745",
            "placeholder": "​",
            "style": "IPY_MODEL_3ede478d731840dcba839f7c23e32bfe",
            "value": "tokenizer.json: 100%"
          }
        },
        "3c33145f7bef4b97aae17debd6a1b111": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e488c2ca1a84a3c8a860e029ea280eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca30bdb50f1e4b01815cd201579c4d6b",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c69edbbaf7404277b4d055ceec7c21c3",
            "value": 665
          }
        },
        "3ede478d731840dcba839f7c23e32bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42258582d29048ffb55f1aa1d25597b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45c2c8a90ced4c9d89c2d4dabbe27745": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e6ba89bc2cb4921bb7e5663b00a3218": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df8db2b7f66b4fd2b2ec45f04b7c3b6d",
            "placeholder": "​",
            "style": "IPY_MODEL_1e315d1f8ddc4a618c897b90e77df162",
            "value": " 665/665 [00:00&lt;00:00, 40.6kB/s]"
          }
        },
        "4fd33b6c22b74cefb3e0756161ce6027": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b3e94f24e4a4ae898959f30a07aa6cd",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba34a5ccfdfb49ef8ba86720be82ccd8",
            "value": 456318
          }
        },
        "538d3a1df1d147ebbbc1c9dd84244745": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "572992a0e6194efd83d5eb0359ebd8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a644c1000cf413c89d58669b606c226": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7aa8094a6324c15ad59c468aefc5f6b",
            "placeholder": "​",
            "style": "IPY_MODEL_2271a1eb600b42609cda870a7b3a211a",
            "value": "config.json: 100%"
          }
        },
        "5fdbf2f68ca1420a8d542ff2ebce3536": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63d3c3c3d1254b05ac64684a4841430e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a9ae6b68803407caa443010973d21a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6210a88e2a645f680099104a6b5f795",
            "placeholder": "​",
            "style": "IPY_MODEL_93cd4de065174ab9b957e49836781678",
            "value": "generation_config.json: 100%"
          }
        },
        "704b0ef901b64e3389af8d9e33be826e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74d27cf2fa1e4fe89042fdb10307f5a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76089b2deb994810a46379c014c54914": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a53ff4ae1a3b4544b468c383fc5a4ae2",
            "placeholder": "​",
            "style": "IPY_MODEL_79342a20ae5d4cb7b9936fc02d60e0ad",
            "value": "merges.txt: 100%"
          }
        },
        "777337d1fb8d4645aa85cc08eae1482e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79342a20ae5d4cb7b9936fc02d60e0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ae26387e066462ea73528c0c7223c81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83918cbdcce24b23bf3e056500ea7b99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85cd0b0abc7a46aaa58fc614e3b60ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a9ae6b68803407caa443010973d21a0",
              "IPY_MODEL_8b8073757893424fb4f382753e42bd97",
              "IPY_MODEL_cd2035b8598d4e899518f6f31214f89a"
            ],
            "layout": "IPY_MODEL_74d27cf2fa1e4fe89042fdb10307f5a8"
          }
        },
        "8907d8321a0c4e93a1afc0edd5c5e12e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b8073757893424fb4f382753e42bd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db58a341cab549428f433ecc6ca7a5a9",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de8b9b9d94814745a471a7a0c6b35c88",
            "value": 124
          }
        },
        "8d0597472073474dab15187e63db8572": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e438e05f89743a1817d810778866ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_254d0794e13c49589008a5b29545aec7",
            "placeholder": "​",
            "style": "IPY_MODEL_ba584a2630cf4354b7f917b25848c381",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 13.0MB/s]"
          }
        },
        "8eba9caabc284601bda2dccd9d481b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93098dc5de7c45eabe51bff0337d1f10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93758134ce924fc196639a80c8d4f63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_077165f005de4a6b87a560a2e7f0e94c",
              "IPY_MODEL_331102a50d934aab9e25c5b40819c5d7",
              "IPY_MODEL_8e438e05f89743a1817d810778866ecf"
            ],
            "layout": "IPY_MODEL_93098dc5de7c45eabe51bff0337d1f10"
          }
        },
        "93cd4de065174ab9b957e49836781678": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "965d65d80b9b48fe98fa3c4eef075256": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcdf41ffdd134398bfaf385ab270d274",
              "IPY_MODEL_0766631d202c42bead24037dd371ba7c",
              "IPY_MODEL_1f5ce74cbc574891975739714c1d0872"
            ],
            "layout": "IPY_MODEL_83918cbdcce24b23bf3e056500ea7b99"
          }
        },
        "9bc36e1c51bb4d129cb6795061584a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dbcef214b2640719ef8b688b115e34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e5980b982d941d7ad6715980ff6235a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bc36e1c51bb4d129cb6795061584a3f",
            "placeholder": "​",
            "style": "IPY_MODEL_c5e415725dd74927ab49a7484e9f8ad7",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.17kB/s]"
          }
        },
        "a3953e6d0b1a4fd0ba52c3db9d219ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a644c1000cf413c89d58669b606c226",
              "IPY_MODEL_3e488c2ca1a84a3c8a860e029ea280eb",
              "IPY_MODEL_4e6ba89bc2cb4921bb7e5663b00a3218"
            ],
            "layout": "IPY_MODEL_10103f494b1a49988068dbc25147c2f7"
          }
        },
        "a53ff4ae1a3b4544b468c383fc5a4ae2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af155b9e6a794c488a7b1b90aa0038b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b26e5b3983c147d9aa064bf4b0ecb298": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ae26387e066462ea73528c0c7223c81",
            "placeholder": "​",
            "style": "IPY_MODEL_1f400633c73c41cab008e1eb40d36ce7",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b6210a88e2a645f680099104a6b5f795": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6d4e89ffacd41fdae6127d3c8c29846": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b788d4456d164f1baf926d8c8a7884af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7aa8094a6324c15ad59c468aefc5f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba34a5ccfdfb49ef8ba86720be82ccd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba584a2630cf4354b7f917b25848c381": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bad968a9c2414047a7da01dd367b86c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcdf41ffdd134398bfaf385ab270d274": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_538d3a1df1d147ebbbc1c9dd84244745",
            "placeholder": "​",
            "style": "IPY_MODEL_b6d4e89ffacd41fdae6127d3c8c29846",
            "value": "model.safetensors: 100%"
          }
        },
        "c26c1c128d2849c9a7bd894e02226ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14ae44d49abd4966b56d200ce0d475b2",
            "placeholder": "​",
            "style": "IPY_MODEL_572992a0e6194efd83d5eb0359ebd8ad",
            "value": " 456k/456k [00:00&lt;00:00, 11.5MB/s]"
          }
        },
        "c28a811dc70c4caca90286e71841572d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c33145f7bef4b97aae17debd6a1b111",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9dbcef214b2640719ef8b688b115e34d",
            "value": 1355256
          }
        },
        "c5e415725dd74927ab49a7484e9f8ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c69edbbaf7404277b4d055ceec7c21c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7378066f04a4f18a9bb453122f6c678": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca1673cda7d040359f3f45388e1fdb2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a6ec1a1618d47ef9396bcec3471e2b5",
              "IPY_MODEL_c28a811dc70c4caca90286e71841572d",
              "IPY_MODEL_2bfa60654c844522aa38191966fda4c2"
            ],
            "layout": "IPY_MODEL_01a300c381d34c859afb497f5d5370ae"
          }
        },
        "ca30bdb50f1e4b01815cd201579c4d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd2035b8598d4e899518f6f31214f89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8907d8321a0c4e93a1afc0edd5c5e12e",
            "placeholder": "​",
            "style": "IPY_MODEL_8eba9caabc284601bda2dccd9d481b60",
            "value": " 124/124 [00:00&lt;00:00, 5.80kB/s]"
          }
        },
        "d4bfd36b012b440c92cb549df2cd5d2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db58a341cab549428f433ecc6ca7a5a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de8b9b9d94814745a471a7a0c6b35c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df8db2b7f66b4fd2b2ec45f04b7c3b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb25091e87a041dc9bcc4570b41e92fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f22ae8c4f3b946f394a5d4178a145ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76089b2deb994810a46379c014c54914",
              "IPY_MODEL_4fd33b6c22b74cefb3e0756161ce6027",
              "IPY_MODEL_c26c1c128d2849c9a7bd894e02226ddf"
            ],
            "layout": "IPY_MODEL_8d0597472073474dab15187e63db8572"
          }
        },
        "f6e8bda5095f48cf89c2eb0932b60c39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
